{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:33.707812Z",
     "start_time": "2024-04-25T03:49:30.409988Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.data import Data"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "4ca648e1653f6bc2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "703cc2509b28b888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:33.770610Z",
     "start_time": "2024-04-25T03:49:33.707812Z"
    }
   },
   "source": [
    "bp_db = pd.read_csv(\"../data/bp_db.csv\", index_col=0)\n",
    "bp_db.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           ENSEMBL          GO\n",
       "0  ENSG00000000003  GO:0039532\n",
       "1  ENSG00000000005  GO:0001937\n",
       "2  ENSG00000000005  GO:0016525\n",
       "3  ENSG00000000419  GO:0006488\n",
       "4  ENSG00000000419  GO:0006506"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSEMBL</th>\n",
       "      <th>GO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>GO:0039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>GO:0001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>GO:0016525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>GO:0006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>GO:0006506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "de83495d06a06d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:40.178015Z",
     "start_time": "2024-04-25T03:49:33.770610Z"
    }
   },
   "source": [
    "counts1 = pd.read_csv(\"../data/counts1.csv\", index_col=0)\n",
    "counts1.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "089357B               14                7              103              241   \n",
       "089366A               11                2              194              511   \n",
       "089412B                8                0              312              450   \n",
       "089425B                9                0              135              496   \n",
       "089687A                4                0               89              267   \n",
       "\n",
       "         ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "089357B               72             2057               30               60   \n",
       "089366A              110             3325               36              111   \n",
       "089412B              106             3751               45              160   \n",
       "089425B              133             2758               26               93   \n",
       "089687A               49             2181               24               75   \n",
       "\n",
       "         ENSG00000001084  ENSG00000001167  ...  ENSGR0000167393  \\\n",
       "089357B              207              367  ...                1   \n",
       "089366A              186              530  ...                0   \n",
       "089412B              325              653  ...                0   \n",
       "089425B              182              620  ...                0   \n",
       "089687A              122              263  ...                0   \n",
       "\n",
       "         ENSGR0000169084  ENSGR0000169093  ENSGR0000178605  ENSGR0000182378  \\\n",
       "089357B                0                0                0                0   \n",
       "089366A                0                0                0                0   \n",
       "089412B                0                0                0                0   \n",
       "089425B                0                0                0                0   \n",
       "089687A                0                0                0                0   \n",
       "\n",
       "         ENSGR0000185291  ENSGR0000198223  ENSGR0000214717  ENSGR0000223511  \\\n",
       "089357B                0                0                0                0   \n",
       "089366A                0                1                0                0   \n",
       "089412B                0                1                0                0   \n",
       "089425B                0                0                0                0   \n",
       "089687A                0                1                0                0   \n",
       "\n",
       "         ENSGR0000223773  \n",
       "089357B                0  \n",
       "089366A                1  \n",
       "089412B                0  \n",
       "089425B                0  \n",
       "089687A                0  \n",
       "\n",
       "[5 rows x 52645 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSGR0000167393</th>\n",
       "      <th>ENSGR0000169084</th>\n",
       "      <th>ENSGR0000169093</th>\n",
       "      <th>ENSGR0000178605</th>\n",
       "      <th>ENSGR0000182378</th>\n",
       "      <th>ENSGR0000185291</th>\n",
       "      <th>ENSGR0000198223</th>\n",
       "      <th>ENSGR0000214717</th>\n",
       "      <th>ENSGR0000223511</th>\n",
       "      <th>ENSGR0000223773</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>089357B</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "      <td>241</td>\n",
       "      <td>72</td>\n",
       "      <td>2057</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>207</td>\n",
       "      <td>367</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089366A</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>511</td>\n",
       "      <td>110</td>\n",
       "      <td>3325</td>\n",
       "      <td>36</td>\n",
       "      <td>111</td>\n",
       "      <td>186</td>\n",
       "      <td>530</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089412B</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>450</td>\n",
       "      <td>106</td>\n",
       "      <td>3751</td>\n",
       "      <td>45</td>\n",
       "      <td>160</td>\n",
       "      <td>325</td>\n",
       "      <td>653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089425B</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>496</td>\n",
       "      <td>133</td>\n",
       "      <td>2758</td>\n",
       "      <td>26</td>\n",
       "      <td>93</td>\n",
       "      <td>182</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089687A</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>267</td>\n",
       "      <td>49</td>\n",
       "      <td>2181</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>122</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52645 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "8f679c3537ff4d32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:40.193713Z",
     "start_time": "2024-04-25T03:49:40.178015Z"
    }
   },
   "source": [
    "pheno1 = pd.read_csv(\"../data/pheno1.csv\", index_col=0)\n",
    "pheno1.drop([\"diagnosis\"], axis=1, inplace=True)\n",
    "pheno1[\"condition\"] = pheno1[\"condition\"].apply(lambda x: 0 if x == \"Control\" else 1)\n",
    "pheno1.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         age sex  lithium  condition\n",
       "089357B   18   F        0          0\n",
       "089366A   19   F        0          0\n",
       "089412B   23   F        0          0\n",
       "089425B   47   F        0          0\n",
       "089687A   52   F        0          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>lithium</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>089357B</th>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089366A</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089412B</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089425B</th>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089687A</th>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6dccdac6a31a835f",
   "metadata": {},
   "source": [
    "# Train Node Embeddings from Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfc2317bcd4658fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:41.209669Z",
     "start_time": "2024-04-25T03:49:40.193713Z"
    }
   },
   "source": [
    "bp_graph = nx.read_gml(\"../data/bp_graph.gml\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1e4c6f44154cac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:41.319226Z",
     "start_time": "2024-04-25T03:49:41.209669Z"
    }
   },
   "source": [
    "bp_db_go = sorted(set(bp_graph.nodes))\n",
    "\n",
    "map_int_go = {int(idx): go for idx, go in enumerate(bp_db_go)}\n",
    "map_go_int = {go: idx for idx, go in map_int_go.items()}\n",
    "\n",
    "_graph = nx.relabel_nodes(bp_graph, map_go_int, copy=False)\n",
    "edge_index = torch.tensor(list(_graph.edges()), dtype=torch.long).t().contiguous()\n",
    "\n",
    "data = Data(x=None, edge_index=edge_index)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "6d464d014f28b6b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:41.506725Z",
     "start_time": "2024-04-25T03:49:41.319226Z"
    }
   },
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=8, walk_length=20,\n",
    "                 context_size=10, walks_per_node=10,\n",
    "                 num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "loader = model.loader(batch_size=4, shuffle=True)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "f8c00d52b2dcc4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:49:41.522352Z",
     "start_time": "2024-04-25T03:49:41.506725Z"
    }
   },
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c53c639ee3271d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:45.521312Z",
     "start_time": "2024-04-25T03:49:41.522352Z"
    }
   },
   "source": [
    "losses = []\n",
    "for epoch in range(1, 100):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 1.3259\n",
      "Epoch: 02, Loss: 1.1262\n",
      "Epoch: 03, Loss: 1.0325\n",
      "Epoch: 04, Loss: 0.9776\n",
      "Epoch: 05, Loss: 0.9390\n",
      "Epoch: 06, Loss: 0.9115\n",
      "Epoch: 07, Loss: 0.8904\n",
      "Epoch: 08, Loss: 0.8741\n",
      "Epoch: 09, Loss: 0.8609\n",
      "Epoch: 10, Loss: 0.8500\n",
      "Epoch: 11, Loss: 0.8404\n",
      "Epoch: 12, Loss: 0.8324\n",
      "Epoch: 13, Loss: 0.8258\n",
      "Epoch: 14, Loss: 0.8198\n",
      "Epoch: 15, Loss: 0.8141\n",
      "Epoch: 16, Loss: 0.8095\n",
      "Epoch: 17, Loss: 0.8057\n",
      "Epoch: 18, Loss: 0.8016\n",
      "Epoch: 19, Loss: 0.7982\n",
      "Epoch: 20, Loss: 0.7954\n",
      "Epoch: 21, Loss: 0.7927\n",
      "Epoch: 22, Loss: 0.7902\n",
      "Epoch: 23, Loss: 0.7882\n",
      "Epoch: 24, Loss: 0.7857\n",
      "Epoch: 25, Loss: 0.7842\n",
      "Epoch: 26, Loss: 0.7825\n",
      "Epoch: 27, Loss: 0.7808\n",
      "Epoch: 28, Loss: 0.7796\n",
      "Epoch: 29, Loss: 0.7781\n",
      "Epoch: 30, Loss: 0.7770\n",
      "Epoch: 31, Loss: 0.7758\n",
      "Epoch: 32, Loss: 0.7750\n",
      "Epoch: 33, Loss: 0.7739\n",
      "Epoch: 34, Loss: 0.7732\n",
      "Epoch: 35, Loss: 0.7723\n",
      "Epoch: 36, Loss: 0.7717\n",
      "Epoch: 37, Loss: 0.7710\n",
      "Epoch: 38, Loss: 0.7705\n",
      "Epoch: 39, Loss: 0.7701\n",
      "Epoch: 40, Loss: 0.7696\n",
      "Epoch: 41, Loss: 0.7691\n",
      "Epoch: 42, Loss: 0.7686\n",
      "Epoch: 43, Loss: 0.7680\n",
      "Epoch: 44, Loss: 0.7678\n",
      "Epoch: 45, Loss: 0.7675\n",
      "Epoch: 46, Loss: 0.7672\n",
      "Epoch: 47, Loss: 0.7666\n",
      "Epoch: 48, Loss: 0.7665\n",
      "Epoch: 49, Loss: 0.7663\n",
      "Epoch: 50, Loss: 0.7659\n",
      "Epoch: 51, Loss: 0.7654\n",
      "Epoch: 52, Loss: 0.7655\n",
      "Epoch: 53, Loss: 0.7652\n",
      "Epoch: 54, Loss: 0.7652\n",
      "Epoch: 55, Loss: 0.7647\n",
      "Epoch: 56, Loss: 0.7647\n",
      "Epoch: 57, Loss: 0.7643\n",
      "Epoch: 58, Loss: 0.7643\n",
      "Epoch: 59, Loss: 0.7641\n",
      "Epoch: 60, Loss: 0.7641\n",
      "Epoch: 61, Loss: 0.7640\n",
      "Epoch: 62, Loss: 0.7638\n",
      "Epoch: 63, Loss: 0.7637\n",
      "Epoch: 64, Loss: 0.7635\n",
      "Epoch: 65, Loss: 0.7634\n",
      "Epoch: 66, Loss: 0.7636\n",
      "Epoch: 67, Loss: 0.7631\n",
      "Epoch: 68, Loss: 0.7630\n",
      "Epoch: 69, Loss: 0.7627\n",
      "Epoch: 70, Loss: 0.7628\n",
      "Epoch: 71, Loss: 0.7627\n",
      "Epoch: 72, Loss: 0.7629\n",
      "Epoch: 73, Loss: 0.7625\n",
      "Epoch: 74, Loss: 0.7626\n",
      "Epoch: 75, Loss: 0.7625\n",
      "Epoch: 76, Loss: 0.7625\n",
      "Epoch: 77, Loss: 0.7624\n",
      "Epoch: 78, Loss: 0.7624\n",
      "Epoch: 79, Loss: 0.7623\n",
      "Epoch: 80, Loss: 0.7623\n",
      "Epoch: 81, Loss: 0.7622\n",
      "Epoch: 82, Loss: 0.7620\n",
      "Epoch: 83, Loss: 0.7621\n",
      "Epoch: 84, Loss: 0.7619\n",
      "Epoch: 85, Loss: 0.7619\n",
      "Epoch: 86, Loss: 0.7619\n",
      "Epoch: 87, Loss: 0.7619\n",
      "Epoch: 88, Loss: 0.7618\n",
      "Epoch: 89, Loss: 0.7620\n",
      "Epoch: 90, Loss: 0.7616\n",
      "Epoch: 91, Loss: 0.7613\n",
      "Epoch: 92, Loss: 0.7614\n",
      "Epoch: 93, Loss: 0.7614\n",
      "Epoch: 94, Loss: 0.7613\n",
      "Epoch: 95, Loss: 0.7613\n",
      "Epoch: 96, Loss: 0.7613\n",
      "Epoch: 97, Loss: 0.7612\n",
      "Epoch: 98, Loss: 0.7611\n",
      "Epoch: 99, Loss: 0.7608\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:45.990151Z",
     "start_time": "2024-04-25T04:00:45.521312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# draw loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "a390a5cf243d293d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "135c3d5095125b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:46.006040Z",
     "start_time": "2024-04-25T04:00:45.990151Z"
    }
   },
   "source": [
    "go_embedding = model()  # go_index -> go_embedding\n",
    "go_embedding.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9917, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e724e321c682bfbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:46.037296Z",
     "start_time": "2024-04-25T04:00:46.006040Z"
    }
   },
   "source": [
    "_embedding = go_embedding.cpu().detach().numpy()\n",
    "\n",
    "map_int_gene = {int(idx): gene for idx, gene in enumerate(counts1.columns)}\n",
    "map_gene_int = {gene: idx for idx, gene in map_int_gene.items()}\n",
    "\n",
    "# convert to gene_index -> go_embedding\n",
    "embedding_gene = np.random.randn(len(counts1.columns), _embedding.shape[1])\n",
    "for idx, gene in map_int_gene.items():\n",
    "    if gene in map_go_int:\n",
    "        embedding_gene[idx] = _embedding[map_go_int[gene]]\n",
    "\n",
    "embedding_gene = torch.tensor(embedding_gene, dtype=torch.float32, device=device)\n",
    "embedding_gene.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52645, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:46.052921Z",
     "start_time": "2024-04-25T04:00:46.037296Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(embedding_gene, '../data/embedding_gene.pt')",
   "id": "30bc7341fb3bbc60",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "93c17bd4cac55149",
   "metadata": {},
   "source": [
    "# process the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e74a2b4749d6ce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:28.994273Z",
     "start_time": "2024-04-25T04:44:28.680903Z"
    }
   },
   "source": [
    "# add age, sex, lithium of pheno1 to counts1\n",
    "tmp_pheno1 = pheno1[[\"age\", \"sex\", \"lithium\"]].apply(lambda x: x.replace(\"M\", 0).replace(\"F\", 1))  # chagne sex to 0, 1\n",
    "counts1_merge = pd.merge(counts1, tmp_pheno1, left_index=True, right_index=True)\n",
    "\n",
    "counts1_merge = (counts1_merge - counts1_merge.mean()) / counts1_merge.std()\n",
    "counts1_merge.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "089357B         2.110648         4.704691        -0.899272        -1.436269   \n",
       "089366A         1.348549         1.129061        -0.091576         0.088378   \n",
       "089412B         0.586450        -0.301190         0.955766        -0.256079   \n",
       "089425B         0.840483        -0.301190        -0.615247         0.003676   \n",
       "089687A        -0.429682        -0.301190        -1.023533        -1.289451   \n",
       "\n",
       "         ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "089357B        -1.132860        -1.111674        -0.804400        -1.458287   \n",
       "089366A        -0.357019        -0.170067        -0.695273        -0.660205   \n",
       "089412B        -0.438687         0.146277        -0.531583         0.106580   \n",
       "089425B         0.112569        -0.591117        -0.877151        -0.941881   \n",
       "089687A        -1.602448        -1.019593        -0.913527        -1.223557   \n",
       "\n",
       "         ENSG00000001084  ENSG00000001167  ...  ENSGR0000178605  \\\n",
       "089357B        -0.629450        -1.040200  ...        -0.152399   \n",
       "089366A        -0.785903        -0.267949  ...        -0.152399   \n",
       "089412B         0.249663         0.314793  ...        -0.152399   \n",
       "089425B        -0.815703         0.158447  ...        -0.152399   \n",
       "089687A        -1.262710        -1.532924  ...        -0.152399   \n",
       "\n",
       "         ENSGR0000182378  ENSGR0000185291  ENSGR0000198223  ENSGR0000214717  \\\n",
       "089357B        -0.453101        -0.212458        -0.502577         -0.45051   \n",
       "089366A        -0.453101        -0.212458        -0.146685         -0.45051   \n",
       "089412B        -0.453101        -0.212458        -0.146685         -0.45051   \n",
       "089425B        -0.453101        -0.212458        -0.502577         -0.45051   \n",
       "089687A        -0.453101        -0.212458        -0.146685         -0.45051   \n",
       "\n",
       "         ENSGR0000223511  ENSGR0000223773       age       sex   lithium  \n",
       "089357B        -0.222561        -0.226593 -2.043569  0.879916 -0.720677  \n",
       "089366A        -0.222561         2.492525 -1.972198  0.879916 -0.720677  \n",
       "089412B        -0.222561        -0.226593 -1.686712  0.879916 -0.720677  \n",
       "089425B        -0.222561        -0.226593  0.026202  0.879916 -0.720677  \n",
       "089687A        -0.222561        -0.226593  0.383059  0.879916 -0.720677  \n",
       "\n",
       "[5 rows x 52648 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSGR0000178605</th>\n",
       "      <th>ENSGR0000182378</th>\n",
       "      <th>ENSGR0000185291</th>\n",
       "      <th>ENSGR0000198223</th>\n",
       "      <th>ENSGR0000214717</th>\n",
       "      <th>ENSGR0000223511</th>\n",
       "      <th>ENSGR0000223773</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>lithium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>089357B</th>\n",
       "      <td>2.110648</td>\n",
       "      <td>4.704691</td>\n",
       "      <td>-0.899272</td>\n",
       "      <td>-1.436269</td>\n",
       "      <td>-1.132860</td>\n",
       "      <td>-1.111674</td>\n",
       "      <td>-0.804400</td>\n",
       "      <td>-1.458287</td>\n",
       "      <td>-0.629450</td>\n",
       "      <td>-1.040200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152399</td>\n",
       "      <td>-0.453101</td>\n",
       "      <td>-0.212458</td>\n",
       "      <td>-0.502577</td>\n",
       "      <td>-0.45051</td>\n",
       "      <td>-0.222561</td>\n",
       "      <td>-0.226593</td>\n",
       "      <td>-2.043569</td>\n",
       "      <td>0.879916</td>\n",
       "      <td>-0.720677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089366A</th>\n",
       "      <td>1.348549</td>\n",
       "      <td>1.129061</td>\n",
       "      <td>-0.091576</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>-0.357019</td>\n",
       "      <td>-0.170067</td>\n",
       "      <td>-0.695273</td>\n",
       "      <td>-0.660205</td>\n",
       "      <td>-0.785903</td>\n",
       "      <td>-0.267949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152399</td>\n",
       "      <td>-0.453101</td>\n",
       "      <td>-0.212458</td>\n",
       "      <td>-0.146685</td>\n",
       "      <td>-0.45051</td>\n",
       "      <td>-0.222561</td>\n",
       "      <td>2.492525</td>\n",
       "      <td>-1.972198</td>\n",
       "      <td>0.879916</td>\n",
       "      <td>-0.720677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089412B</th>\n",
       "      <td>0.586450</td>\n",
       "      <td>-0.301190</td>\n",
       "      <td>0.955766</td>\n",
       "      <td>-0.256079</td>\n",
       "      <td>-0.438687</td>\n",
       "      <td>0.146277</td>\n",
       "      <td>-0.531583</td>\n",
       "      <td>0.106580</td>\n",
       "      <td>0.249663</td>\n",
       "      <td>0.314793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152399</td>\n",
       "      <td>-0.453101</td>\n",
       "      <td>-0.212458</td>\n",
       "      <td>-0.146685</td>\n",
       "      <td>-0.45051</td>\n",
       "      <td>-0.222561</td>\n",
       "      <td>-0.226593</td>\n",
       "      <td>-1.686712</td>\n",
       "      <td>0.879916</td>\n",
       "      <td>-0.720677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089425B</th>\n",
       "      <td>0.840483</td>\n",
       "      <td>-0.301190</td>\n",
       "      <td>-0.615247</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.112569</td>\n",
       "      <td>-0.591117</td>\n",
       "      <td>-0.877151</td>\n",
       "      <td>-0.941881</td>\n",
       "      <td>-0.815703</td>\n",
       "      <td>0.158447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152399</td>\n",
       "      <td>-0.453101</td>\n",
       "      <td>-0.212458</td>\n",
       "      <td>-0.502577</td>\n",
       "      <td>-0.45051</td>\n",
       "      <td>-0.222561</td>\n",
       "      <td>-0.226593</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.879916</td>\n",
       "      <td>-0.720677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089687A</th>\n",
       "      <td>-0.429682</td>\n",
       "      <td>-0.301190</td>\n",
       "      <td>-1.023533</td>\n",
       "      <td>-1.289451</td>\n",
       "      <td>-1.602448</td>\n",
       "      <td>-1.019593</td>\n",
       "      <td>-0.913527</td>\n",
       "      <td>-1.223557</td>\n",
       "      <td>-1.262710</td>\n",
       "      <td>-1.532924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152399</td>\n",
       "      <td>-0.453101</td>\n",
       "      <td>-0.212458</td>\n",
       "      <td>-0.146685</td>\n",
       "      <td>-0.45051</td>\n",
       "      <td>-0.222561</td>\n",
       "      <td>-0.226593</td>\n",
       "      <td>0.383059</td>\n",
       "      <td>0.879916</td>\n",
       "      <td>-0.720677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52648 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "6352a7375c960f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:29.009898Z",
     "start_time": "2024-04-25T04:44:28.994273Z"
    }
   },
   "source": [
    "bp_db_genes = set(bp_db.ENSEMBL)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "7676409a345d9cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.339010Z",
     "start_time": "2024-04-25T04:44:29.009898Z"
    }
   },
   "source": [
    "dataset = []\n",
    "input_dim = None\n",
    "\n",
    "for row in counts1_merge.iterrows():\n",
    "    idx = row[0]\n",
    "    values = row[1]\n",
    "    _data = {\n",
    "        \"gene_idx\": [],\n",
    "        \"gene_value\": [],\n",
    "        \"other_info\": []\n",
    "    }\n",
    "    for k, v in values.items():\n",
    "        if k in map_gene_int:\n",
    "            _data[\"gene_idx\"].append(map_gene_int[k])\n",
    "            _data[\"gene_value\"].append(v)\n",
    "        else:\n",
    "            _data[\"other_info\"].append(v)\n",
    "    dataset.append(_data)\n",
    "    if input_dim is None:\n",
    "        input_dim = [len(_data[\"gene_idx\"]), len(_data[\"gene_value\"]), len(_data[\"other_info\"])]\n",
    "\n",
    "input_dim"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52645, 52645, 3]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "6db3f7cf05dbade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.355059Z",
     "start_time": "2024-04-25T04:44:37.339010Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx]\n",
    "        gene_idx = torch.tensor(sample['gene_idx'], dtype=torch.long, device=device)\n",
    "        gene_value = torch.tensor(sample['gene_value'], dtype=torch.float, device=device)\n",
    "        other_info = torch.tensor(sample['other_info'], dtype=torch.float, device=device)\n",
    "\n",
    "        return {\n",
    "            'gene_idx': gene_idx,\n",
    "            'gene_value': gene_value,\n",
    "            'other_info': other_info\n",
    "        }, torch.tensor(self.y[idx], dtype=torch.long, device=device)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "7138ab82252b3773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.370691Z",
     "start_time": "2024-04-25T04:44:37.355059Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset\n",
    "y = pheno1[\"condition\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(len(X_train), len(X_test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 134\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "84130e64e014ae3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.511316Z",
     "start_time": "2024-04-25T04:44:37.370691Z"
    }
   },
   "source": [
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DNN Classifier with Gene Embedding",
   "id": "adefc2c87b795b20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.526941Z",
     "start_time": "2024-04-25T04:44:37.511316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, node_embedding, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = node_embedding\n",
    "        #self.embedding.requires_grad = False\n",
    "        self.fc0_1 = nn.Linear(9, 128)\n",
    "        self.fc0_2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(sum(input_dim), 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.05)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        gene_idx = X['gene_idx']  # (B, N_1)\n",
    "        gene_value = X['gene_value']  # (B, N_1)\n",
    "        other_info = X['other_info']  # (B, N_2)\n",
    "\n",
    "        gene_embedding = self.embedding[gene_idx]  # (B, N_1, 8)\n",
    "        gene_embedding = torch.concat([gene_embedding, gene_value.unsqueeze(2)], dim=2)  # (B, N_1, 9)\n",
    "        gene_embedding = self.fc0_1(gene_embedding)  # (B, N_1, 128)\n",
    "        gene_embedding = self.relu(gene_embedding)\n",
    "        gene_embedding = self.fc0_2(gene_embedding).squeeze(2)  # (B, N_1)\n",
    "\n",
    "        output = torch.cat([gene_embedding, gene_value, other_info], dim=1)  # (B, N_1 * 2 + N_3)\n",
    "\n",
    "        output = self.fc1(output)  # (B, 512)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    "        output = self.fc2(output)  # (B, 128)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout2(output)\n",
    "\n",
    "        return self.fc3(output)  # (B, 2)"
   ],
   "id": "8aae4c7930920bca",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.542566Z",
     "start_time": "2024-04-25T04:44:37.526941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for X, y in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Assuming your model's forward method automatically handles padding, then no need to pack sequence here\n",
    "        predictions = model(X)\n",
    "\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Compute the number of correct predictions\n",
    "        _, predicted_classes = predictions.max(dim=1)\n",
    "        correct_predictions = (predicted_classes == y).float()  # Convert to float for summation\n",
    "        total_correct += correct_predictions.sum().item()\n",
    "        total_instances += y.size(0)\n",
    "\n",
    "    epoch_acc = total_correct / total_instances\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc\n",
    "\n",
    "#train_loss, train_acc = train(model, train_loader, optimizer, criterion)"
   ],
   "id": "399cda7df431190b",
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "21b4baa715ce7bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.558191Z",
     "start_time": "2024-04-25T04:44:37.542566Z"
    }
   },
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in iterator:\n",
    "            predictions = model(X)\n",
    "\n",
    "            loss = criterion(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Compute the number of correct predictions\n",
    "            _, predicted_classes = predictions.max(dim=1)\n",
    "            correct_predictions = (predicted_classes == y).float()  # Convert to float for summation\n",
    "            total_correct += correct_predictions.sum().item()\n",
    "            total_instances += y.size(0)\n",
    "\n",
    "    epoch_acc = total_correct / total_instances\n",
    "    return epoch_loss / len(iterator), epoch_acc"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "3c7554b7e500ba06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:44:37.573816Z",
     "start_time": "2024-04-25T04:44:37.558191Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
    "    return elapsed_mins, elapsed_secs, elapsed_time"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "ec76852d146ec0ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:46:47.900296Z",
     "start_time": "2024-04-25T04:44:37.573816Z"
    }
   },
   "source": [
    "embedding_gene = torch.load('../data/embedding_gene.pt')\n",
    "model = MyModel(node_embedding=embedding_gene, input_dim=input_dim, output_dim=2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n",
    "\n",
    "N_EPOCHS = 40\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "best_valid_acc = 0\n",
    "\n",
    "elapsed_times = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs, elapsed_time = epoch_time(start_time, end_time)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        #torch.save(model.state_dict(), '../data/final_model.pt')\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs:.3f}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.3f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.3f}%')\n",
    "\n",
    "avg_elapsed_time = sum(elapsed_times) / len(elapsed_times)\n",
    "print(f'Avg Epoch Time: {avg_elapsed_time:.3f}s')\n",
    "print(f'Best Val. Loss: {best_valid_loss:.3f} | Best Val. Acc: {best_valid_acc * 100:.3f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2.986s\n",
      "\tTrain Loss: 0.668 | Train Acc: 60.323%\n",
      "\t Val. Loss: 0.664 |  Val. Acc: 61.940%\n",
      "Epoch: 02 | Epoch Time: 0m 3.141s\n",
      "\tTrain Loss: 0.576 | Train Acc: 73.871%\n",
      "\t Val. Loss: 0.638 |  Val. Acc: 61.940%\n",
      "Epoch: 03 | Epoch Time: 0m 3.157s\n",
      "\tTrain Loss: 0.468 | Train Acc: 85.161%\n",
      "\t Val. Loss: 0.660 |  Val. Acc: 61.940%\n",
      "Epoch: 04 | Epoch Time: 0m 3.235s\n",
      "\tTrain Loss: 0.379 | Train Acc: 90.323%\n",
      "\t Val. Loss: 0.581 |  Val. Acc: 67.910%\n",
      "Epoch: 05 | Epoch Time: 0m 3.234s\n",
      "\tTrain Loss: 0.292 | Train Acc: 96.452%\n",
      "\t Val. Loss: 0.556 |  Val. Acc: 67.910%\n",
      "Epoch: 06 | Epoch Time: 0m 3.219s\n",
      "\tTrain Loss: 0.219 | Train Acc: 97.419%\n",
      "\t Val. Loss: 0.478 |  Val. Acc: 83.582%\n",
      "Epoch: 07 | Epoch Time: 0m 3.282s\n",
      "\tTrain Loss: 0.156 | Train Acc: 99.032%\n",
      "\t Val. Loss: 0.510 |  Val. Acc: 73.134%\n",
      "Epoch: 08 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.113 | Train Acc: 99.355%\n",
      "\t Val. Loss: 0.520 |  Val. Acc: 74.627%\n",
      "Epoch: 09 | Epoch Time: 0m 3.297s\n",
      "\tTrain Loss: 0.086 | Train Acc: 99.355%\n",
      "\t Val. Loss: 0.527 |  Val. Acc: 73.881%\n",
      "Epoch: 10 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.061 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.517 |  Val. Acc: 71.642%\n",
      "Epoch: 11 | Epoch Time: 0m 3.281s\n",
      "\tTrain Loss: 0.053 | Train Acc: 99.677%\n",
      "\t Val. Loss: 0.442 |  Val. Acc: 79.851%\n",
      "Epoch: 12 | Epoch Time: 0m 3.234s\n",
      "\tTrain Loss: 0.041 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 76.119%\n",
      "Epoch: 13 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.036 | Train Acc: 99.677%\n",
      "\t Val. Loss: 0.462 |  Val. Acc: 78.358%\n",
      "Epoch: 14 | Epoch Time: 0m 3.282s\n",
      "\tTrain Loss: 0.028 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.409 |  Val. Acc: 82.836%\n",
      "Epoch: 15 | Epoch Time: 0m 3.298s\n",
      "\tTrain Loss: 0.025 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 79.104%\n",
      "Epoch: 16 | Epoch Time: 0m 3.266s\n",
      "\tTrain Loss: 0.021 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 76.866%\n",
      "Epoch: 17 | Epoch Time: 0m 3.297s\n",
      "\tTrain Loss: 0.019 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.460 |  Val. Acc: 78.358%\n",
      "Epoch: 18 | Epoch Time: 0m 3.267s\n",
      "\tTrain Loss: 0.016 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.455 |  Val. Acc: 79.104%\n",
      "Epoch: 19 | Epoch Time: 0m 3.297s\n",
      "\tTrain Loss: 0.014 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.471 |  Val. Acc: 78.358%\n",
      "Epoch: 20 | Epoch Time: 0m 3.266s\n",
      "\tTrain Loss: 0.015 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.463 |  Val. Acc: 79.104%\n",
      "Epoch: 21 | Epoch Time: 0m 3.266s\n",
      "\tTrain Loss: 0.013 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 76.119%\n",
      "Epoch: 22 | Epoch Time: 0m 3.312s\n",
      "\tTrain Loss: 0.011 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 78.358%\n",
      "Epoch: 23 | Epoch Time: 0m 3.220s\n",
      "\tTrain Loss: 0.010 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 79.851%\n",
      "Epoch: 24 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.010 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 79.851%\n",
      "Epoch: 25 | Epoch Time: 0m 3.219s\n",
      "\tTrain Loss: 0.009 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.463 |  Val. Acc: 79.851%\n",
      "Epoch: 26 | Epoch Time: 0m 3.298s\n",
      "\tTrain Loss: 0.008 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.499 |  Val. Acc: 76.866%\n",
      "Epoch: 27 | Epoch Time: 0m 3.266s\n",
      "\tTrain Loss: 0.008 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.494 |  Val. Acc: 76.866%\n",
      "Epoch: 28 | Epoch Time: 0m 3.234s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 78.358%\n",
      "Epoch: 29 | Epoch Time: 0m 3.204s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.510 |  Val. Acc: 76.119%\n",
      "Epoch: 30 | Epoch Time: 0m 3.313s\n",
      "\tTrain Loss: 0.008 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.502 |  Val. Acc: 78.358%\n",
      "Epoch: 31 | Epoch Time: 0m 3.266s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.485 |  Val. Acc: 78.358%\n",
      "Epoch: 32 | Epoch Time: 0m 3.313s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 79.104%\n",
      "Epoch: 33 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 79.104%\n",
      "Epoch: 34 | Epoch Time: 0m 3.298s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 79.104%\n",
      "Epoch: 35 | Epoch Time: 0m 3.297s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.507 |  Val. Acc: 78.358%\n",
      "Epoch: 36 | Epoch Time: 0m 3.219s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.509 |  Val. Acc: 77.612%\n",
      "Epoch: 37 | Epoch Time: 0m 3.281s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.492 |  Val. Acc: 79.104%\n",
      "Epoch: 38 | Epoch Time: 0m 3.250s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 79.104%\n",
      "Epoch: 39 | Epoch Time: 0m 3.234s\n",
      "\tTrain Loss: 0.004 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.514 |  Val. Acc: 77.612%\n",
      "Epoch: 40 | Epoch Time: 0m 3.219s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 79.104%\n",
      "Avg Epoch Time: 3.250s\n",
      "Best Val. Loss: 0.409 | Best Val. Acc: 83.582%\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DNN Classifier without Gene Embedding",
   "id": "155fcb573ee47813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:46:47.916403Z",
     "start_time": "2024-04-25T04:46:47.900296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MyModelBaseline(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(sum(input_dim[1:]), 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.05)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        gene_value = X['gene_value']  # (B, N_1)\n",
    "        other_info = X['other_info']  # (B, N_2)\n",
    "        output = torch.cat([gene_value, other_info], dim=1)  # (B, N_1 + N_3)\n",
    "\n",
    "        output = self.fc1(output)  # (B, 512)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    "        output = self.fc2(output)  # (B, 128)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout2(output)\n",
    "\n",
    "        return self.fc3(output)  # (B, 2)"
   ],
   "id": "4a73737bd0358716",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:48:43.569265Z",
     "start_time": "2024-04-25T04:46:47.916403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MyModelBaseline(input_dim=input_dim, output_dim=2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n",
    "\n",
    "N_EPOCHS = 40\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "best_valid_acc = 0\n",
    "\n",
    "elapsed_times = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs, elapsed_time = epoch_time(start_time, end_time)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        #torch.save(model.state_dict(), '../data/final_model.pt')\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs:.3f}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.3f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.3f}%')\n",
    "\n",
    "avg_elapsed_time = sum(elapsed_times) / len(elapsed_times)\n",
    "print(f'Avg Epoch Time: {avg_elapsed_time:.3f}s')\n",
    "print(f'Best Val. Loss: {best_valid_loss:.3f} | Best Val. Acc: {best_valid_acc * 100:.3f}%')"
   ],
   "id": "2497ed8dd5f3652f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2.563s\n",
      "\tTrain Loss: 0.668 | Train Acc: 59.032%\n",
      "\t Val. Loss: 0.682 |  Val. Acc: 61.194%\n",
      "Epoch: 02 | Epoch Time: 0m 2.626s\n",
      "\tTrain Loss: 0.577 | Train Acc: 77.742%\n",
      "\t Val. Loss: 0.644 |  Val. Acc: 65.672%\n",
      "Epoch: 03 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.495 | Train Acc: 85.806%\n",
      "\t Val. Loss: 0.632 |  Val. Acc: 64.925%\n",
      "Epoch: 04 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.422 | Train Acc: 89.677%\n",
      "\t Val. Loss: 0.607 |  Val. Acc: 70.896%\n",
      "Epoch: 05 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.344 | Train Acc: 93.548%\n",
      "\t Val. Loss: 0.570 |  Val. Acc: 71.642%\n",
      "Epoch: 06 | Epoch Time: 0m 2.641s\n",
      "\tTrain Loss: 0.278 | Train Acc: 96.774%\n",
      "\t Val. Loss: 0.576 |  Val. Acc: 70.149%\n",
      "Epoch: 07 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.215 | Train Acc: 98.065%\n",
      "\t Val. Loss: 0.540 |  Val. Acc: 74.627%\n",
      "Epoch: 08 | Epoch Time: 0m 3.594s\n",
      "\tTrain Loss: 0.162 | Train Acc: 99.677%\n",
      "\t Val. Loss: 0.544 |  Val. Acc: 73.881%\n",
      "Epoch: 09 | Epoch Time: 0m 3.141s\n",
      "\tTrain Loss: 0.131 | Train Acc: 99.355%\n",
      "\t Val. Loss: 0.532 |  Val. Acc: 73.134%\n",
      "Epoch: 10 | Epoch Time: 0m 2.500s\n",
      "\tTrain Loss: 0.105 | Train Acc: 99.677%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 76.866%\n",
      "Epoch: 11 | Epoch Time: 0m 2.626s\n",
      "\tTrain Loss: 0.083 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.507 |  Val. Acc: 74.627%\n",
      "Epoch: 12 | Epoch Time: 0m 2.626s\n",
      "\tTrain Loss: 0.069 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 76.119%\n",
      "Epoch: 13 | Epoch Time: 0m 3.626s\n",
      "\tTrain Loss: 0.054 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 75.373%\n",
      "Epoch: 14 | Epoch Time: 0m 3.110s\n",
      "\tTrain Loss: 0.043 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 76.866%\n",
      "Epoch: 15 | Epoch Time: 0m 2.578s\n",
      "\tTrain Loss: 0.039 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.496 |  Val. Acc: 77.612%\n",
      "Epoch: 16 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.034 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 76.119%\n",
      "Epoch: 17 | Epoch Time: 0m 3.610s\n",
      "\tTrain Loss: 0.029 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.481 |  Val. Acc: 76.119%\n",
      "Epoch: 18 | Epoch Time: 0m 3.203s\n",
      "\tTrain Loss: 0.026 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 76.119%\n",
      "Epoch: 19 | Epoch Time: 0m 2.516s\n",
      "\tTrain Loss: 0.024 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 76.119%\n",
      "Epoch: 20 | Epoch Time: 0m 2.610s\n",
      "\tTrain Loss: 0.023 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.435 |  Val. Acc: 76.119%\n",
      "Epoch: 21 | Epoch Time: 0m 3.578s\n",
      "\tTrain Loss: 0.019 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 77.612%\n",
      "Epoch: 22 | Epoch Time: 0m 3.094s\n",
      "\tTrain Loss: 0.018 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.482 |  Val. Acc: 76.866%\n",
      "Epoch: 23 | Epoch Time: 0m 2.516s\n",
      "\tTrain Loss: 0.017 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.479 |  Val. Acc: 76.866%\n",
      "Epoch: 24 | Epoch Time: 0m 2.641s\n",
      "\tTrain Loss: 0.015 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.479 |  Val. Acc: 76.866%\n",
      "Epoch: 25 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.014 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 79.104%\n",
      "Epoch: 26 | Epoch Time: 0m 3.625s\n",
      "\tTrain Loss: 0.014 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 79.104%\n",
      "Epoch: 27 | Epoch Time: 0m 3.125s\n",
      "\tTrain Loss: 0.011 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 76.866%\n",
      "Epoch: 28 | Epoch Time: 0m 2.500s\n",
      "\tTrain Loss: 0.012 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 76.866%\n",
      "Epoch: 29 | Epoch Time: 0m 2.609s\n",
      "\tTrain Loss: 0.010 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 76.866%\n",
      "Epoch: 30 | Epoch Time: 0m 2.641s\n",
      "\tTrain Loss: 0.010 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.478 |  Val. Acc: 77.612%\n",
      "Epoch: 31 | Epoch Time: 0m 3.626s\n",
      "\tTrain Loss: 0.009 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 78.358%\n",
      "Epoch: 32 | Epoch Time: 0m 3.078s\n",
      "\tTrain Loss: 0.009 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 78.358%\n",
      "Epoch: 33 | Epoch Time: 0m 2.501s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 76.866%\n",
      "Epoch: 34 | Epoch Time: 0m 2.609s\n",
      "\tTrain Loss: 0.009 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.501 |  Val. Acc: 78.358%\n",
      "Epoch: 35 | Epoch Time: 0m 3.579s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.507 |  Val. Acc: 78.358%\n",
      "Epoch: 36 | Epoch Time: 0m 3.079s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.489 |  Val. Acc: 76.866%\n",
      "Epoch: 37 | Epoch Time: 0m 2.532s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 77.612%\n",
      "Epoch: 38 | Epoch Time: 0m 2.625s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 77.612%\n",
      "Epoch: 39 | Epoch Time: 0m 2.641s\n",
      "\tTrain Loss: 0.006 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.506 |  Val. Acc: 77.612%\n",
      "Epoch: 40 | Epoch Time: 0m 3.594s\n",
      "\tTrain Loss: 0.007 | Train Acc: 100.000%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 77.612%\n",
      "Avg Epoch Time: 2.888s\n",
      "Best Val. Loss: 0.435 | Best Val. Acc: 79.104%\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
